{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "156a45d18d914974bdaff89d122af3e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c25e8ee2a1564efbb8152a28b32eb8d0",
              "IPY_MODEL_2cffadb5427a4777a1b921fabff0a20e",
              "IPY_MODEL_c8c1642229444679aca83a4e530f9408"
            ],
            "layout": "IPY_MODEL_c9cff81e3c70496d87ac58f299e8b092"
          }
        },
        "c25e8ee2a1564efbb8152a28b32eb8d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_689fa4e7880c49d98b8fc3c4e52bccfe",
            "placeholder": "​",
            "style": "IPY_MODEL_d430049c563241889ec3b4d89c266808",
            "value": "Map: 100%"
          }
        },
        "2cffadb5427a4777a1b921fabff0a20e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23452144b12446bebf7dadc81ad2e280",
            "max": 150000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c3d44a6c45dc4c14907089599b36f3dd",
            "value": 150000
          }
        },
        "c8c1642229444679aca83a4e530f9408": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5ed178433f6484a81828e9aa873ae81",
            "placeholder": "​",
            "style": "IPY_MODEL_d4de82f2e8364b358cca8d053fcfe684",
            "value": " 150000/150000 [01:02&lt;00:00, 1840.45 examples/s]"
          }
        },
        "c9cff81e3c70496d87ac58f299e8b092": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "689fa4e7880c49d98b8fc3c4e52bccfe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d430049c563241889ec3b4d89c266808": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23452144b12446bebf7dadc81ad2e280": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3d44a6c45dc4c14907089599b36f3dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a5ed178433f6484a81828e9aa873ae81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4de82f2e8364b358cca8d053fcfe684": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqWNORTpa3YW",
        "outputId": "4b3f890e-a7e1-4102-e984-9b662ea34eac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.2.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies\n",
        "!pip install transformers datasets torch scikit-learn\n",
        "\n",
        "# Import required libraries\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "from datasets import Dataset\n",
        "import pandas as pd\n",
        "import re\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# import re\n",
        "\n",
        "# # Load CSV with error skipping\n",
        "# file_path = \"/content/Bug_data.csv\"\n",
        "# df = pd.read_csv(\n",
        "#     file_path,\n",
        "#     quoting=3,  # QUOTE_NONE\n",
        "#     quotechar='\"',\n",
        "#     escapechar='\\\\',\n",
        "#     on_bad_lines='warn',\n",
        "#     engine='python'  # More lenient parsing\n",
        "# )\n",
        "\n",
        "# # Fill NaNs in text columns with empty string\n",
        "# df[\"Column1.title\"] = df[\"Column1.title\"].fillna(\"\")\n",
        "# df[\"Column1.body\"] = df[\"Column1.body\"].fillna(\"\")\n",
        "\n",
        "# # Drop rows with missing labels\n",
        "# df = df.dropna(subset=[\"Column1.label\"])\n",
        "\n",
        "# # Define clean_text function\n",
        "# def clean_text(text):\n",
        "#     text = str(text).lower()\n",
        "#     text = re.sub(r\"http\\S+|www\\S+\", \"\", text)  # Remove URLs\n",
        "#     text = re.sub(r\"\\[.?\\]|\\{.?\\}|\\(|\\)\", \"\", text)  # Remove markdown symbols\n",
        "#     text = re.sub(r\"[^a-z0-9\\s]\", \"\", text)  # Keep only alphanumeric & spaces\n",
        "#     text = re.sub(r\"\\s+\", \" \", text).strip()  # Remove extra spaces\n",
        "#     return text\n",
        "\n",
        "# # Apply cleaning to both title and body, then concatenate\n",
        "# df[\"cleaned_text\"] = df[\"Column1.title\"].apply(clean_text) + \" \" + df[\"Column1.body\"].apply(clean_text)\n",
        "\n",
        "# # Rename label column for clarity\n",
        "# df = df.rename(columns={\"Column1.label\": \"label\"})\n",
        "\n",
        "# # Final record count\n",
        "# print(f\"Final number of records: {len(df)}\")\n",
        "\n",
        "\n",
        "# # Check raw row count\n",
        "# raw_df = pd.read_csv(file_path, quoting=3, on_bad_lines='warn')\n",
        "# print(f\"Total rows loaded initially: {len(raw_df)}\")\n",
        "\n",
        "# # Check for expected columns\n",
        "# print(\"Columns in dataset:\", raw_df.columns.tolist())\n",
        "\n",
        "# # Check missing values (if any)\n",
        "# print(\"Missing values:\\n\", raw_df.isnull().sum())\n",
        "\n",
        "# # Check number of rows with non-null labels\n",
        "# non_null_labels = raw_df[\"Column1.label\"].notnull().sum()\n",
        "# print(f\"Rows with non-null labels: {non_null_labels}\")\n"
      ],
      "metadata": {
        "id": "KBXnYb1DRZp_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_file = \"/content/Bug_data.csv\"\n",
        "output_file = \"/content/Bug_data_cleaned_fixed.csv\"\n",
        "\n",
        "cleaned_lines = []\n",
        "total_lines = 0\n",
        "fixed_lines = 0\n",
        "skipped_lines = 0\n",
        "\n",
        "with open(input_file, \"r\", encoding=\"utf-8\") as infile:\n",
        "    for line in infile:\n",
        "        total_lines += 1\n",
        "        parts = [p.strip().strip('\"') for p in line.strip().split(\",\")]\n",
        "\n",
        "        if len(parts) == 3:\n",
        "            cleaned_lines.append(\",\".join(parts) + \"\\n\")\n",
        "        elif len(parts) > 3:\n",
        "            # Fix: Combine everything except the last field into title/body\n",
        "            label = parts[-1]\n",
        "            content = \" \".join(parts[:-1])  # Merge the rest\n",
        "            # Split content into title/body (basic heuristic: first sentence as title)\n",
        "            if \".\" in content:\n",
        "                split_index = content.find(\".\") + 1\n",
        "                title = content[:split_index].strip()\n",
        "                body = content[split_index:].strip()\n",
        "            else:\n",
        "                title = content\n",
        "                body = \"\"\n",
        "\n",
        "            cleaned_line = f'\"{title}\",\"{body}\",\"{label}\"\\n'\n",
        "            cleaned_lines.append(cleaned_line)\n",
        "            fixed_lines += 1\n",
        "        else:\n",
        "            skipped_lines += 1  # Less than 3 fields, likely bad row\n",
        "\n",
        "# Save fixed dataset\n",
        "with open(output_file, \"w\", encoding=\"utf-8\") as outfile:\n",
        "    outfile.writelines(cleaned_lines)\n",
        "\n",
        "print(f\"Total lines processed     : {total_lines}\")\n",
        "print(f\"Valid original lines      : {total_lines - fixed_lines - skipped_lines}\")\n",
        "print(f\"Fixed lines (merged cols) : {fixed_lines}\")\n",
        "print(f\"Skipped bad lines         : {skipped_lines}\")\n",
        "print(f\"Cleaned file saved as     : {output_file}\")\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/Bug_data_cleaned_fixed.csv\", header=None, names=[\"Column1.title\", \"Column1.body\", \"Column1.label\"])\n",
        "print(f\"Records loaded after cleaning and fixing: {len(df)}\")\n",
        "\n",
        "from google.colab import files\n",
        "files.download('/content/Bug_data_cleaned_fixed.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "SzvR_BXsUQv4",
        "outputId": "7df2afed-63a7-4869-8214-9d775a5bc9b7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total lines processed     : 150001\n",
            "Valid original lines      : 55262\n",
            "Fixed lines (merged cols) : 94739\n",
            "Skipped bad lines         : 0\n",
            "Cleaned file saved as     : /content/Bug_data_cleaned_fixed.csv\n",
            "Records loaded after cleaning and fixing: 150001\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c888ae64-2b3b-4e5a-9f5a-450bb2b4a335\", \"Bug_data_cleaned_fixed.csv\", 91028265)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# os.kill(os.getpid(), 9)\n"
      ],
      "metadata": {
        "id": "GdguaIRAvqi0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -U --force-reinstall transformers\n",
        "# import transformers\n",
        "# print(transformers.__version__)"
      ],
      "metadata": {
        "id": "F_Zlu30swlnl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install latest dependencies\n",
        "!pip install --upgrade transformers datasets evaluate scikit-learn --quiet\n",
        "\n",
        "# Imports\n",
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "from datasets import Dataset\n",
        "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
        "import evaluate\n",
        "\n",
        "# Load CSV\n",
        "file_path = \"/content/Bug_data_cleaned_fixed.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Text cleaning\n",
        "def clean_text(text):\n",
        "    text = str(text).lower()\n",
        "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)\n",
        "    text = re.sub(r\"\\[.*?\\]|\\{.*?\\}|\\(|\\)\", \"\", text)\n",
        "    text = re.sub(r\"[^a-z0-9\\s]\", \"\", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text\n",
        "\n",
        "# Apply cleaning\n",
        "df[\"cleaned_text\"] = df[\"Column1.title\"].apply(clean_text) + \" \" + df[\"Column1.body\"].apply(clean_text)\n",
        "df = df.rename(columns={\"Column1.label\": \"label\"})\n",
        "\n",
        "# Convert to HF dataset\n",
        "dataset = Dataset.from_pandas(df[[\"cleaned_text\", \"label\"]])\n",
        "\n",
        "# Tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"cleaned_text\"], padding=\"max_length\", truncation=True, max_length=256)\n",
        "\n",
        "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Train/test split\n",
        "split_dataset = tokenized_dataset.train_test_split(test_size=0.2)\n",
        "train_dataset = split_dataset[\"train\"]\n",
        "test_dataset = split_dataset[\"test\"]\n",
        "\n",
        "# Load model\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"microsoft/codebert-base\", num_labels=2)\n",
        "\n",
        "# Metric computation function\n",
        "accuracy_metric = evaluate.load(\"accuracy\")\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='binary')\n",
        "\n",
        "    # Print classification report\n",
        "    print(\"\\nClassification Report:\\n\")\n",
        "    print(classification_report(labels, predictions, digits=4))\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": accuracy[\"accuracy\"],\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": f1\n",
        "    }\n",
        "\n",
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./codebert_bug_classifier\",\n",
        "    # evaluation_strategy=\"epoch\",\n",
        "    # save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=1,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=500,\n",
        "    fp16=True  # Enable mixed precision\n",
        ")\n",
        "\n",
        "# Trainer setup\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# Train model\n",
        "print(f\"Training samples: {len(train_dataset)}\")\n",
        "print(f\"Testing samples : {len(test_dataset)}\")\n",
        "trainer.train()\n",
        "\n",
        "# Final evaluation\n",
        "trainer.evaluate()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "156a45d18d914974bdaff89d122af3e7",
            "c25e8ee2a1564efbb8152a28b32eb8d0",
            "2cffadb5427a4777a1b921fabff0a20e",
            "c8c1642229444679aca83a4e530f9408",
            "c9cff81e3c70496d87ac58f299e8b092",
            "689fa4e7880c49d98b8fc3c4e52bccfe",
            "d430049c563241889ec3b4d89c266808",
            "23452144b12446bebf7dadc81ad2e280",
            "c3d44a6c45dc4c14907089599b36f3dd",
            "a5ed178433f6484a81828e9aa873ae81",
            "d4de82f2e8364b358cca8d053fcfe684"
          ]
        },
        "id": "7DekUQKxdLYh",
        "outputId": "cd0ad5d2-8d6b-43a2-cc78-6a5d36235d77"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/150000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "156a45d18d914974bdaff89d122af3e7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/codebert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-8-92b80610260e>:84: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training samples: 120000\n",
            "Testing samples : 30000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m22071a1288\u001b[0m (\u001b[33mteamml\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.10"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250510_152802-g302x0sa</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/teamml/huggingface/runs/g302x0sa' target=\"_blank\">./codebert_bug_classifier</a></strong> to <a href='https://wandb.ai/teamml/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/teamml/huggingface' target=\"_blank\">https://wandb.ai/teamml/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/teamml/huggingface/runs/g302x0sa' target=\"_blank\">https://wandb.ai/teamml/huggingface/runs/g302x0sa</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7500' max='7500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7500/7500 39:58, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.434600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.375800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.345800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.344800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.342100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.332100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.336700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.328200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.327600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.331400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.318100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.324400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.320700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.328500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.321000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1875' max='1875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1875/1875 01:43]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8451    0.8690    0.8569     13361\n",
            "           1     0.8924    0.8720    0.8821     16639\n",
            "\n",
            "    accuracy                         0.8707     30000\n",
            "   macro avg     0.8687    0.8705    0.8695     30000\n",
            "weighted avg     0.8713    0.8707    0.8709     30000\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.32238438725471497,\n",
              " 'eval_accuracy': 0.8707,\n",
              " 'eval_precision': 0.8923739237392374,\n",
              " 'eval_recall': 0.8720475990143638,\n",
              " 'eval_f1': 0.8820936806589866,\n",
              " 'eval_runtime': 103.9417,\n",
              " 'eval_samples_per_second': 288.623,\n",
              " 'eval_steps_per_second': 18.039,\n",
              " 'epoch': 1.0}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "print(transformers.__version__)"
      ],
      "metadata": {
        "id": "DsDYMcmLudnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VeHT1Sm1RW7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate\n",
        "import numpy as np\n",
        "import evaluate\n",
        "\n",
        "\n",
        "# Load accuracy metric\n",
        "accuracy_metric = evaluate.load(\"accuracy\")\n",
        "\n",
        "# Define function to compute accuracy\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)  # Convert logits to class labels\n",
        "\n",
        "    # Compute accuracy\n",
        "    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)\n",
        "\n",
        "    return {\"accuracy\": accuracy[\"accuracy\"]}  # Ensure correct key\n",
        "\n",
        "# Update Trainer with accuracy computation\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics  # Add metric calculation\n",
        ")\n",
        "\n",
        "# Evaluate again\n",
        "results = trainer.evaluate()\n",
        "\n",
        "# Print available keys for debugging\n",
        "print(\"Available keys in results:\", results.keys())\n",
        "\n",
        "# Print accuracy if available\n",
        "if \"accuracy\" in results:\n",
        "    print(f\"Model Accuracy: {results['accuracy'] * 100:.2f}%\")\n",
        "else:\n",
        "    print(\"Error: Accuracy key not found in evaluation results.\")\n"
      ],
      "metadata": {
        "id": "ShPywk_0nW-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import evaluate\n",
        "\n",
        "# Load accuracy metric\n",
        "accuracy_metric = evaluate.load(\"accuracy\")\n",
        "\n",
        "# Define function to compute accuracy\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "\n",
        "    # Debugging: Print structure of eval_pred\n",
        "    print(\"Logits shape:\", np.array(logits).shape)\n",
        "    print(\"Labels shape:\", np.array(labels).shape)\n",
        "    print(\"Sample logits:\", logits[:2])  # Print first two samples for inspection\n",
        "    print(\"Sample labels:\", labels[:2])\n",
        "\n",
        "    # Convert logits to class predictions\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "    # Compute accuracy\n",
        "    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)\n",
        "\n",
        "    return {\"accuracy\": accuracy[\"accuracy\"]}  # Ensure correct key\n",
        "\n",
        "# Update Trainer with accuracy computation\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# Run evaluation again\n",
        "results = trainer.evaluate()\n",
        "print(\"Evaluation Results:\", results)\n",
        "print(f\"Model Accuracy: {results['eval_accuracy'] * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "0isqKw-UpCre",
        "outputId": "c0d35dc2-ba2c-460a-bf76-d7a033a396e4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-ebcd680bf03c>:26: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1875' max='1875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1875/1875 01:47]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logits shape: (30000, 2)\n",
            "Labels shape: (30000,)\n",
            "Sample logits: [[-2.3457031  2.4335938]\n",
            " [ 1.8457031 -2.0410156]]\n",
            "Sample labels: [1 0]\n",
            "Evaluation Results: {'eval_loss': 0.32238438725471497, 'eval_model_preparation_time': 0.0052, 'eval_accuracy': 0.8707, 'eval_runtime': 107.6705, 'eval_samples_per_second': 278.628, 'eval_steps_per_second': 17.414}\n",
            "Model Accuracy: 87.07%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Move model to the same device it's trained on\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Define test input (title + body)\n",
        "test_text = \"issue type:  bug report       ansible version:  ansible 1.8.1, but present at least since 1.5.0       environment:  ubuntu 14.10, with ansible in a virtualenv  jinja2==2.7.3 markupsafe==0.23 pyyaml==3.11 ansible==1.8.1 argparse==1.2.1 ecdsa==0.11 paramiko==1.15.1 pycrypto==2.6.1 wsgiref==0.1.2       summary:  similar to gh-5914, the copy module fails when there's json with variables in  the content field, _and_ it is run with  with_items .       steps to reproduce:      yaml - hosts: localhost   tasks:   - copy:         content: \\  {{item}} \\          dest: /tmp/bug     with_items:     - \\ 123\\            expected results:  a file containing   \\ 123\\   .       actual results:      play  localhost                                                                   gathering facts                                                                  ok:  localhost   task:  copy                                                                      failed:  localhost  =>  item=123  => {\\ failed\\ : true, \\ item\\ : \\ 123\\ } msg: could not write content temp file: expected a character buffer object  fatal: all hosts have already failed -- aborting  play recap                                                                                  to retry, use: --limit @/home/username/jsonbug.retry  localhost                  : ok=1    changed=0    unreachable=0    failed=1\"\n",
        "\n",
        "\n",
        "# Tokenize the input and move it to the same device as the model\n",
        "inputs = tokenizer(test_text, padding=\"max_length\", truncation=True, max_length=256, return_tensors=\"pt\").to(device)\n",
        "\n",
        "# Get model prediction\n",
        "model.eval()  # Set model to evaluation mode\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "# Extract logits and convert to class label\n",
        "logits = outputs.logits\n",
        "predicted_class = torch.argmax(logits, dim=-1).item()\n",
        "\n",
        "# Print result\n",
        "if predicted_class == 0:\n",
        "    print(\"Prediction: This issue is classified as a BUG 🐞\")\n",
        "else:\n",
        "    print(\"Prediction: This issue is NOT a bug ✅\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdpBf6T8R7ng",
        "outputId": "f69ccb04-93b8-45ee-faee-379688a2b6d9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: This issue is classified as a BUG 🐞\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Define directory where to save the model\n",
        "save_directory = \"/content/codebert_bug_classifier_model\"\n",
        "\n",
        "# Save the trained model\n",
        "trainer.save_model(save_directory)\n",
        "\n",
        "# Save tokenizer\n",
        "tokenizer.save_pretrained(save_directory)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lU_tNpKFfy6",
        "outputId": "ca3b5374-ee51-4011-b866-ebae163a741c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/codebert_bug_classifier_model/tokenizer_config.json',\n",
              " '/content/codebert_bug_classifier_model/special_tokens_map.json',\n",
              " '/content/codebert_bug_classifier_model/vocab.json',\n",
              " '/content/codebert_bug_classifier_model/merges.txt',\n",
              " '/content/codebert_bug_classifier_model/added_tokens.json',\n",
              " '/content/codebert_bug_classifier_model/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Create a ZIP of the folder\n",
        "shutil.make_archive(save_directory, 'zip', save_directory)\n",
        "from google.colab import files\n",
        "files.download(save_directory + \".zip\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "gmy3rDfBFrpF",
        "outputId": "04fb96c6-43d2-426b-f697-1d3726902bea"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_29a60c62-59c1-4e52-85d8-a1153790c460\", \"codebert_bug_classifier_model.zip\", 464337274)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_jP7pUclYbge"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}